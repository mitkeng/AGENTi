{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "BWDrWeXLT8IP",
        "ZZesBAlNerTL",
        "6eWSMCNjdTTL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Dependencies"
      ],
      "metadata": {
        "id": "BWDrWeXLT8IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #### Install Dependencies\n",
        "%%capture\n",
        "!wget https://github.com/mitkeng/AGENTi/raw/refs/heads/main/multi-models/agentI_anom_model.zip\n",
        "!wget https://github.com/mitkeng/AGENTi/raw/refs/heads/main/multi-models/agentI_reg_model.zip\n",
        "!wget https://github.com/mitkeng/AGENTi/raw/refs/heads/main/multi-models/autoencoder_model.keras\n",
        "\n",
        "\n",
        "\n",
        "!pip install rdkit\n",
        "!pip install -q condacolab\n",
        "!pip install ydf -U -qq\n",
        "!pip install tensorflow_decision_forests -U -qq\n",
        "!pip install trainer\n",
        "!pip install PubChemPy\n",
        "!pip install cirpy\n",
        "!pip install ase\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "import condacolab\n",
        "\n"
      ],
      "metadata": {
        "id": "-DId6ORx7rPy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install rdkit\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from numpy.core.arrayprint import printoptions\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "4KtcYrN-_mZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import cirpy\n",
        "import pubchempy as pcp\n",
        "from rdkit import Chem\n",
        "import os\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from pubchempy import get_compounds, Compound\n",
        "import pubchempy as pcp\n",
        "from rdkit import Chem\n",
        "import os\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "import sys\n",
        "import re\n",
        "from tensorflow.keras.layers import IntegerLookup\n",
        "from tensorflow.keras.layers import Normalization\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "from tensorflow.python.ops.gen_dataset_ops import filter_dataset_eager_fallback\n",
        "from tensorflow.python.ops.gen_math_ops import Max\n",
        "from statistics import*\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import quote\n",
        "from copy import deepcopy\n",
        "import pubchempy as pcp\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit import Chem\n",
        "import os\n"
      ],
      "metadata": {
        "id": "3BioCyx3_c58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Query System(s)"
      ],
      "metadata": {
        "id": "sQhYV3rCUFXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Enter Query System(s)\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import ase\n",
        "import cirpy\n",
        "import pubchempy as pcp\n",
        "from rdkit import Chem\n",
        "import os\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from pubchempy import get_compounds, Compound\n",
        "import pubchempy as pcp\n",
        "from rdkit import Chem\n",
        "import os\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "import sys\n",
        "import re\n",
        "from tensorflow.keras.layers import IntegerLookup\n",
        "from tensorflow.keras.layers import Normalization\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "from tensorflow.python.ops.gen_dataset_ops import filter_dataset_eager_fallback\n",
        "from tensorflow.python.ops.gen_math_ops import Max\n",
        "from statistics import*\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import quote\n",
        "from copy import deepcopy\n",
        "import pubchempy as pcp\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit import Chem\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ase import io\n",
        "from ase.io import read, write\n",
        "import os\n",
        "import shutil\n",
        "import __main__\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "def get_query():\n",
        "  ex_count=0\n",
        "  for q in os.listdir():\n",
        "    fi_list = q.split(\".\")\n",
        "    if 'csv' in fi_list and \"protomers\" not in fi_list and \"results_data\" not in fi_list:\n",
        "      ex_count=+1\n",
        "      return q\n",
        "  if ex_count==0:\n",
        "    return \"ask_user\"\n",
        "\n",
        "try:\n",
        "  os.remove(\"results_data.csv\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  os.remove(\"single_quiry.csv\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "input_query = get_query()\n",
        "input_query2 = [input_query]\n",
        "\n",
        "\n",
        "if \"ask_user\"  in input_query:\n",
        "  file_name2 = \"single_quiry.csv\"\n",
        "  query_file = open(file_name2,\"w\")\n",
        "  input_query2=[input(\"Enter SMILE: \")]\n",
        "  for l in range(len(input_query2)):\n",
        "\n",
        "    print(input_query2[l].strip(), file=query_file)\n",
        "  query_file.close()\n",
        "  file_name = file_name2\n",
        "else:\n",
        "  file_name = input_query\n",
        "  pass\n",
        "\n",
        "\n",
        "smile_file = open(file_name)\n",
        "smi_list_ = []\n",
        "\n",
        "for fi in smile_file:\n",
        "  if \".csv\" in input_query:\n",
        "    smi= fi.strip()\n",
        "    smi_list_.append(smi.strip())\n",
        "  else:\n",
        "    smi=fi.strip()\n",
        "    smi_list_= smi\n",
        "    smi_list =[smi_list_]\n",
        "if \".csv\" in input_query:\n",
        "  smi_list = [item for item in smi_list_ if item != \"\"]\n"
      ],
      "metadata": {
        "id": "dNfb0hf4KWjm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML Protomer Shift Detection"
      ],
      "metadata": {
        "id": "ZZesBAlNerTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Excute to continue\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "import sys\n",
        "import cirpy\n",
        "import pubchempy as pcp\n",
        "from rdkit import Chem\n",
        "import os\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from pubchempy import get_compounds, Compound\n",
        "import pubchempy as pcp\n",
        "from rdkit import Chem\n",
        "from tensorflow.keras.layers import IntegerLookup\n",
        "from tensorflow.keras.layers import Normalization\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "from tensorflow.python.ops.gen_dataset_ops import filter_dataset_eager_fallback\n",
        "from tensorflow.python.ops.gen_math_ops import Max\n",
        "from statistics import*\n",
        "\n",
        "import zipfile\n",
        "\n",
        "try:\n",
        "  with zipfile.ZipFile('apciesi_anom_model.zip', 'r') as zip_:\n",
        "    zip_.extractall('apciesi_anom_model')\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  with zipfile.ZipFile('apciesi_reg_model.zip', 'r') as zip_:\n",
        "    zip_.extractall('apciesi_reg_model')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "atom_radii = {\"H\":1.2, \"C\":1.7, \"N\":1.55, \"O\":1.52,\"P\": 1.8, \"S\": 1.8,\"F\": 1.35, \"Cl\":1.75, \"Br\":1.83}\n",
        "atom_mass = {\"H\":1, \"C\":12, \"N\":14, \"O\":16,\"P\": 31, \"S\": 32,\"F\": 19, \"Cl\":35.34, \"Br\":79.9}\n",
        "electro_neg= {\"C\":2.55, \"O\":3.44, \"H\": 2.2, \"N\": 3.04, \"P\": 2.19, \"S\": 2.58,\"F\": 3.98, \"Cl\":3.16, \"Br\":2.96}\n",
        "ionize_E= {\"C\":11.26, \"O\":13.618, \"H\": 13.598, \"N\": 14.534, \"P\": 10.487, \"S\": 10.360,\"F\": 17.423, \"Cl\":12.968, \"Br\":11.8}\n",
        "polari =  {\"C\":1.76, \"O\":0.802, \"H\": 0.667, \"N\": 1.1, \"P\": 3.63, \"S\": 2.9,\"F\": 0.557, \"Cl\":2.18, \"Br\":3.05}\n",
        "\n",
        "\n",
        "test_file =\"protomers.csv\"\n",
        "\n",
        "\n",
        "new_csv = open(test_file, \"w\")\n",
        "print(\"smile,radii_mass2,electronic2,double_bond2,triple_bond2,hetero2,halogen,ring2,TPSA,VSA,logP,pos_charge,neg_charge\", file = new_csv)\n",
        "\n",
        "\n",
        "\n",
        "for mi in range(len(smi_list)):\n",
        "  smile_list=[]\n",
        "  try:\n",
        "    for s in smi_list[mi]:\n",
        "      s = s.strip().split('\\n')\n",
        "\n",
        "      s2 = s[0].strip(',')\n",
        "      smile = s2.split(',')\n",
        "      smile_list.append(smile[0])\n",
        "\n",
        "    atom_list=[]\n",
        "\n",
        "    for M in smile_list:\n",
        "      halogen_count=0\n",
        "      third_row = 0\n",
        "\n",
        "      atom_list.append(M.strip())\n",
        "\n",
        "      double_bond = atom_list.count(\"=\")\n",
        "      double_bond2= double_bond\n",
        "      triple_bond = atom_list.count(\"#\")\n",
        "      triple_bond2=triple_bond\n",
        "      third_row += atom_list.count(\"S\")\n",
        "      third_row += atom_list.count(\"P\")\n",
        "      halogen_count+= atom_list.count(\"l\")\n",
        "      halogen_count+= atom_list.count(\"F\")\n",
        "      halogen_count+= atom_list.count(\"r\")\n",
        "      halogen_count+= atom_list.count(\"I\")\n",
        "      molecule_set = set(atom_list)\n",
        "      hetero_set = set(atom_list)\n",
        "      try:\n",
        "        molecule_set.remove('(')\n",
        "        molecule_set.remove(')')\n",
        "      except KeyError:\n",
        "        next\n",
        "\n",
        "      molecule_list = list(molecule_set)\n",
        "\n",
        "      total_radii=[]\n",
        "      total_mass=[]\n",
        "      total_EN=[]\n",
        "      total_IE=[]\n",
        "      total_pol=[]\n",
        "      total_hetero = []\n",
        "      total_atom = []\n",
        "      total_ring=[]\n",
        "\n",
        "      for a in range(len(molecule_list)):\n",
        "\n",
        "        b=atom_list.count(molecule_list[a])\n",
        "        if molecule_list[a].isnumeric():\n",
        "          all_ring=atom_list.count(molecule_list[a])\n",
        "          total_ring.append(all_ring)\n",
        "        try:\n",
        "          atom_ra = atom_radii[molecule_list[a]]*b\n",
        "          atom_ma = atom_mass[molecule_list[a]]*b\n",
        "          el_neg = electro_neg[molecule_list[a]]*b\n",
        "\n",
        "          ion_E = ionize_E[molecule_list[a]]*b\n",
        "          polarizability = polari[molecule_list[a]]*b\n",
        "          total_radii.append(atom_ra)\n",
        "          total_mass.append(atom_ma)\n",
        "          total_EN.append(el_neg)\n",
        "          total_IE.append(ion_E)\n",
        "          total_pol.append(polarizability)\n",
        "        except KeyError:\n",
        "          next\n",
        "\n",
        "        if molecule_list[a].isalpha() and molecule_list[a] != \"H\" and molecule_list[a]!=\"C\":\n",
        "          hetero=atom_list.count(molecule_list[a])\n",
        "          total_hetero.append(hetero)\n",
        "        if molecule_list[a].isalpha():\n",
        "          all_atom=atom_list.count(molecule_list[a])\n",
        "          total_atom.append(all_atom)\n",
        "\n",
        "\n",
        "      sm = Chem.MolFromSmiles(smi_list[mi])\n",
        "\n",
        "      TPSA = round(Descriptors.TPSA(sm),2)\n",
        "      VSA = float(round(Descriptors.VSA_EState2(sm),2))\n",
        "      logP = round(Descriptors.MolLogP(sm),2)\n",
        "      pos_charge = atom_list.count(\"+\")\n",
        "      neg_charge = atom_list.count(\"-\")\n",
        "      radii,mass,EN,IE,Polar, hetero=sum(total_radii),sum(total_mass),sum(total_EN),sum(total_IE),sum(total_pol), sum(total_hetero)\n",
        "      hetero2 = hetero\n",
        "      tot_atom = sum(total_atom)\n",
        "      tot_ring = sum(total_ring)/2\n",
        "      radii_mass2 =round((radii*tot_atom)/sum(total_mass),2)\n",
        "      electronic2 = round((IE*EN)/(Polar*tot_atom ),2)\n",
        "      ring2 = int(tot_ring)\n",
        "      features=smi_list[mi],radii_mass2,electronic2,double_bond2,triple_bond2,hetero2,halogen_count,ring2,TPSA,VSA,logP,pos_charge, neg_charge\n",
        "\n",
        "    new_csv = open(test_file, \"a\")\n",
        "    print(features[0],\",\",features[1],\",\",features[2],\",\",features[3],\",\",features[4],\",\",features[5],\",\",features[6],\",\",features[7],\",\",features[8],\",\",features[9],\",\",features[10],\",\",features[11],\",\",features[12],file=new_csv)\n",
        "    new_csv.close()\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5CydMkkkXroQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Excute to continue\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler,Normalizer,RobustScaler,StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "auto_mode = load_model(\"autoencoder_model.keras\")\n",
        "\n",
        "scaler = Normalizer()\n",
        "\n",
        "\n",
        "\n",
        "df_TOTAL = pd.read_csv('protomers.csv')\n",
        "df_TOTAL.pop('smile')\n",
        "TOTAL_array = np.array(df_TOTAL)\n",
        "scaled_TOTAL_data = scaler.fit_transform(TOTAL_array)\n",
        "reconstruction_errors = np.mean(np.power(scaled_TOTAL_data - auto_mode.predict(scaled_TOTAL_data),2 ), axis=1)\n",
        "st_dev = 0.0627\n",
        "norm_mean = 0.0456\n",
        "anomalies = [reconstruction_errors> (st_dev)]\n",
        "\n",
        "count_anom = []\n",
        "\n",
        "for i in anomalies[0].tolist():\n",
        "\n",
        "  if str(i) ==\"True\":\n",
        "    count_anom.append(\"True\")\n",
        "  else:\n",
        "    count_anom.append(\"False\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ODwBnix2FP1u",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##results\n",
        "%%capture\n",
        "\n",
        "import ydf\n",
        "\n",
        "import zipfile\n",
        "def unzip():\n",
        "  for z in  os.listdir():\n",
        "    if \"zip\" in z:\n",
        "      zip_file_path = f'{z}'\n",
        "      extract_to_path = f'{z.replace('.zip','')}'\n",
        "      os.makedirs(extract_to_path, exist_ok=True)\n",
        "      with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "          zip_ref.extractall(extract_to_path)\n",
        "\n",
        "\n",
        "try:\n",
        "  extract_zip = unzip()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "anom_model=ydf.load_model(\"agentI_anom_model\")\n",
        "reg_model=ydf.load_model(\"agentI_reg_model\")\n",
        "\n",
        "test_dat = pd.read_csv(\"protomers.csv\")\n",
        "\n",
        "prediction1 = anom_model.predict(test_dat)\n",
        "prediction2 = reg_model.predict(test_dat)\n",
        "\n",
        "\n",
        "index_list = []\n",
        "anom_score = []\n",
        "for p in range(len(prediction1)):\n",
        "  if mean([prediction1[p],prediction2[p]])+reconstruction_errors[p]/st_dev>1.4:\n",
        "    anom_score.append(round(mean([prediction1[p],prediction2[p]])+reconstruction_errors[p]/st_dev,2))\n",
        "    index_list.append(int(str(test_dat[p:p+1][\"smile\"]).split()[0]))\n",
        "    print('yes')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pQr4jtWS6DXw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "dErjg7Qwcmjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Results Preparation and Output\n",
        "import csv\n",
        "import pubchempy as pcp\n",
        "import requests\n",
        "def cactussearch2(ids):\n",
        "\n",
        "      smile_search = pcp.get_compounds(ids, 'smiles')[0]\n",
        "      cids = smile_search.cid\n",
        "\n",
        "      compound_name = get_compound_name_from_cid(cids)\n",
        "      return compound_name\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_compound_name_from_cid(cid):\n",
        "  \"\"\"Retrieves the compound name from a PubChem CID using PUG REST.\"\"\"\n",
        "  url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/synonyms/TXT\"\n",
        "  response = requests.get(url)\n",
        "  response.raise_for_status()\n",
        "  synonyms = response.text.strip().split('\\n')\n",
        "  return synonyms\n",
        "\n",
        "\n",
        "results_file = open(\"results_data.csv\",\"w\")\n",
        "\n",
        "print(\"ChemID,SMILE,Threshold,A-Score\",file=results_file)\n",
        "results_file.close()\n",
        "for i in range(len(index_list)):\n",
        "  try:\n",
        "    results_file = open(\"results_data.csv\",\"a\")\n",
        "    nam = cactussearch2(test_dat.iloc[index_list[i]][\"smile\"])\n",
        "    nam = [x.replace(\",\",\"\") for x in nam]\n",
        "    anom_smile = test_dat.iloc[index_list[i]][\"smile\"]\n",
        "    print(\"{},{},1.40,{}\".format(nam[0],anom_smile,anom_score[i]),file=results_file)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "results_file.close()\n",
        "\n",
        "results_show = pd.read_csv(\"results_data.csv\")\n",
        "results_show"
      ],
      "metadata": {
        "id": "ZwUhjcap6aUR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}